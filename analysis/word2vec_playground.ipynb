{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Review the relevant models: bag-of-words, Word2Vec, Doc2Vec\n",
    "\n",
    "- Load and preprocess the training and test corpora (see Corpus)\n",
    "\n",
    "- Train a Doc2Vec Model model using the training corpus\n",
    "\n",
    "- Demonstrate how the trained model can be used to infer a Vector\n",
    "\n",
    "- Assess the model\n",
    "\n",
    "- Test the model on the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pprint\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### practise bag-of-words with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "# Create a set of frequent words\n",
    "stoplist = set('for a of the and to in'.split(' '))\n",
    "# Lowercase each document, split it by white space and filter out stopwords\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in text_corpus]\n",
    "\n",
    "# Count word frequencies\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Only keep words that appear more than once\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "pprint.pprint(processed_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, we want to associate each word in the corpus with a unique integer ID. We can do this using the gensim.corpora.Dictionary class. This dictionary defines the vocabulary of all words that our processing knows about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-20 10:01:58,278 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-03-20 10:01:58,279 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 0,\n",
       " 'human': 1,\n",
       " 'interface': 2,\n",
       " 'response': 3,\n",
       " 'survey': 4,\n",
       " 'system': 5,\n",
       " 'time': 6,\n",
       " 'user': 7,\n",
       " 'eps': 8,\n",
       " 'trees': 9,\n",
       " 'graph': 10,\n",
       " 'minors': 11}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppose we wanted to vectorize the phrase “Human computer interaction” (note that this phrase was not in our original corpus). We can create the bag-of-word representation for a document using the doc2bow method of the dictionary, which returns a sparse representation of the word counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "pprint.pprint(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)],\n",
      " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
      " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
      " [(1, 1), (5, 2), (8, 1)],\n",
      " [(3, 1), (6, 1), (7, 1)],\n",
      " [(9, 1)],\n",
      " [(9, 1), (10, 1)],\n",
      " [(9, 1), (10, 1), (11, 1)],\n",
      " [(4, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "pprint.pprint(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-20 10:02:05,883 : INFO : collecting document frequencies\n",
      "2020-03-20 10:02:05,884 : INFO : PROGRESS: processing document #0\n",
      "2020-03-20 10:02:05,885 : INFO : calculating IDF weights for 9 documents and 12 features (28 matrix non-zeros)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 0.5898341626740045), (11, 0.8075244024440723)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "# train the model\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "# transform the \"system minors\" string\n",
    "words = \"system minors\".lower().split()\n",
    "print(tfidf[dictionary.doc2bow(words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-20 10:02:09,752 : INFO : creating sparse index\n",
      "2020-03-20 10:02:09,753 : INFO : creating sparse matrix from corpus\n",
      "2020-03-20 10:02:09,753 : INFO : PROGRESS: at document #0\n",
      "2020-03-20 10:02:09,754 : INFO : created <9x12 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 28 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "from gensim import similarities\n",
    "\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0), (1, 0.32448703), (2, 0.41707572), (3, 0.7184812), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "query_document = 'system engineering'.split()\n",
    "query_bow = dictionary.doc2bow(query_document)\n",
    "sims = index[tfidf[query_bow]]\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read this output? Document 3 has a similarity score of 0.718=72%, document 2 has a similarity score of 42% etc. We can make this slightly more readable by sorting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.7184812\n",
      "2 0.41707572\n",
      "1 0.32448703\n",
      "0 0.0\n",
      "4 0.0\n",
      "5 0.0\n",
      "6 0.0\n",
      "7 0.0\n",
      "8 0.0\n"
     ]
    }
   ],
   "source": [
    "for document_number, score in sorted(enumerate(sims), key = lambda x: x[1], reverse=True):\n",
    "    print(document_number, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "# Set file names for train and test data\n",
    "test_data_dir = os.path.join(gensim.__path__[0], 'test', 'test_data')\n",
    "lee_train_file = os.path.join(test_data_dir, 'lee_background.cor')\n",
    "lee_test_file = os.path.join(test_data_dir, 'lee.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smart_open\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "train_corpus = list(read_corpus(lee_train_file))\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['hundreds', 'of', 'people', 'have', 'been', 'forced', 'to', 'vacate', 'their', 'homes', 'in', 'the', 'southern', 'highlands', 'of', 'new', 'south', 'wales', 'as', 'strong', 'winds', 'today', 'pushed', 'huge', 'bushfire', 'towards', 'the', 'town', 'of', 'hill', 'top', 'new', 'blaze', 'near', 'goulburn', 'south', 'west', 'of', 'sydney', 'has', 'forced', 'the', 'closure', 'of', 'the', 'hume', 'highway', 'at', 'about', 'pm', 'aedt', 'marked', 'deterioration', 'in', 'the', 'weather', 'as', 'storm', 'cell', 'moved', 'east', 'across', 'the', 'blue', 'mountains', 'forced', 'authorities', 'to', 'make', 'decision', 'to', 'evacuate', 'people', 'from', 'homes', 'in', 'outlying', 'streets', 'at', 'hill', 'top', 'in', 'the', 'new', 'south', 'wales', 'southern', 'highlands', 'an', 'estimated', 'residents', 'have', 'left', 'their', 'homes', 'for', 'nearby', 'mittagong', 'the', 'new', 'south', 'wales', 'rural', 'fire', 'service', 'says', 'the', 'weather', 'conditions', 'which', 'caused', 'the', 'fire', 'to', 'burn', 'in', 'finger', 'formation', 'have', 'now', 'eased', 'and', 'about', 'fire', 'units', 'in', 'and', 'around', 'hill', 'top', 'are', 'optimistic', 'of', 'defending', 'all', 'properties', 'as', 'more', 'than', 'blazes', 'burn', 'on', 'new', 'year', 'eve', 'in', 'new', 'south', 'wales', 'fire', 'crews', 'have', 'been', 'called', 'to', 'new', 'fire', 'at', 'gunning', 'south', 'of', 'goulburn', 'while', 'few', 'details', 'are', 'available', 'at', 'this', 'stage', 'fire', 'authorities', 'says', 'it', 'has', 'closed', 'the', 'hume', 'highway', 'in', 'both', 'directions', 'meanwhile', 'new', 'fire', 'in', 'sydney', 'west', 'is', 'no', 'longer', 'threatening', 'properties', 'in', 'the', 'cranebrook', 'area', 'rain', 'has', 'fallen', 'in', 'some', 'parts', 'of', 'the', 'illawarra', 'sydney', 'the', 'hunter', 'valley', 'and', 'the', 'north', 'coast', 'but', 'the', 'bureau', 'of', 'meteorology', 'claire', 'richards', 'says', 'the', 'rain', 'has', 'done', 'little', 'to', 'ease', 'any', 'of', 'the', 'hundred', 'fires', 'still', 'burning', 'across', 'the', 'state', 'the', 'falls', 'have', 'been', 'quite', 'isolated', 'in', 'those', 'areas', 'and', 'generally', 'the', 'falls', 'have', 'been', 'less', 'than', 'about', 'five', 'millimetres', 'she', 'said', 'in', 'some', 'places', 'really', 'not', 'significant', 'at', 'all', 'less', 'than', 'millimetre', 'so', 'there', 'hasn', 'been', 'much', 'relief', 'as', 'far', 'as', 'rain', 'is', 'concerned', 'in', 'fact', 'they', 've', 'probably', 'hampered', 'the', 'efforts', 'of', 'the', 'firefighters', 'more', 'because', 'of', 'the', 'wind', 'gusts', 'that', 'are', 'associated', 'with', 'those', 'thunderstorms'], tags=[0]),\n",
       " TaggedDocument(words=['indian', 'security', 'forces', 'have', 'shot', 'dead', 'eight', 'suspected', 'militants', 'in', 'night', 'long', 'encounter', 'in', 'southern', 'kashmir', 'the', 'shootout', 'took', 'place', 'at', 'dora', 'village', 'some', 'kilometers', 'south', 'of', 'the', 'kashmiri', 'summer', 'capital', 'srinagar', 'the', 'deaths', 'came', 'as', 'pakistani', 'police', 'arrested', 'more', 'than', 'two', 'dozen', 'militants', 'from', 'extremist', 'groups', 'accused', 'of', 'staging', 'an', 'attack', 'on', 'india', 'parliament', 'india', 'has', 'accused', 'pakistan', 'based', 'lashkar', 'taiba', 'and', 'jaish', 'mohammad', 'of', 'carrying', 'out', 'the', 'attack', 'on', 'december', 'at', 'the', 'behest', 'of', 'pakistani', 'military', 'intelligence', 'military', 'tensions', 'have', 'soared', 'since', 'the', 'raid', 'with', 'both', 'sides', 'massing', 'troops', 'along', 'their', 'border', 'and', 'trading', 'tit', 'for', 'tat', 'diplomatic', 'sanctions', 'yesterday', 'pakistan', 'announced', 'it', 'had', 'arrested', 'lashkar', 'taiba', 'chief', 'hafiz', 'mohammed', 'saeed', 'police', 'in', 'karachi', 'say', 'it', 'is', 'likely', 'more', 'raids', 'will', 'be', 'launched', 'against', 'the', 'two', 'groups', 'as', 'well', 'as', 'other', 'militant', 'organisations', 'accused', 'of', 'targetting', 'india', 'military', 'tensions', 'between', 'india', 'and', 'pakistan', 'have', 'escalated', 'to', 'level', 'not', 'seen', 'since', 'their', 'war'], tags=[1])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Now, we’ll instantiate a Doc2Vec model with a vector size with 50 dimensions and iterating over the training corpus 40 times. We set the minimum word count to 2 in order to discard words with very few occurrences. (Without a variety of representative examples, retraining such infrequent words can often make a model worse!) Typical iteration counts in the published Paragraph Vector paper results, using 10s-of-thousands to millions of docs, are 10-20. More iterations take more time and eventually reach a point of diminishing returns.\n",
    "\n",
    "However, this is a very very small dataset (300 documents) with shortish documents (a few hundred words). Adding training passes can sometimes help with such small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-20 10:22:50,222 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2020-03-20 10:22:50,223 : INFO : collecting all words and their counts\n",
      "2020-03-20 10:22:50,223 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-03-20 10:22:50,233 : INFO : collected 6981 word types and 300 unique tags from a corpus of 300 examples and 58152 words\n",
      "2020-03-20 10:22:50,233 : INFO : Loading a fresh vocabulary\n",
      "2020-03-20 10:22:50,243 : INFO : effective_min_count=2 retains 3955 unique words (56% of original 6981, drops 3026)\n",
      "2020-03-20 10:22:50,244 : INFO : effective_min_count=2 leaves 55126 word corpus (94% of original 58152, drops 3026)\n",
      "2020-03-20 10:22:50,250 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2020-03-20 10:22:50,250 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2020-03-20 10:22:50,251 : INFO : downsampling leaves estimated 42390 word corpus (76.9% of prior 55126)\n",
      "2020-03-20 10:22:50,256 : INFO : estimated required memory for 3955 words and 50 dimensions: 3619500 bytes\n",
      "2020-03-20 10:22:50,256 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-20 10:23:11,470 : INFO : training model with 3 workers on 3955 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-03-20 10:23:11,547 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,558 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,559 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,559 : INFO : EPOCH - 1 : training on 58152 raw words (42642 effective words) took 0.1s, 490133 effective words/s\n",
      "2020-03-20 10:23:11,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,588 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,589 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,589 : INFO : EPOCH - 2 : training on 58152 raw words (42791 effective words) took 0.0s, 1513507 effective words/s\n",
      "2020-03-20 10:23:11,618 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,626 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,627 : INFO : EPOCH - 3 : training on 58152 raw words (42695 effective words) took 0.0s, 1173253 effective words/s\n",
      "2020-03-20 10:23:11,654 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,654 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,655 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,655 : INFO : EPOCH - 4 : training on 58152 raw words (42608 effective words) took 0.0s, 1623989 effective words/s\n",
      "2020-03-20 10:23:11,684 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,686 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,687 : INFO : EPOCH - 5 : training on 58152 raw words (42786 effective words) took 0.0s, 1402850 effective words/s\n",
      "2020-03-20 10:23:11,712 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,713 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,714 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,715 : INFO : EPOCH - 6 : training on 58152 raw words (42672 effective words) took 0.0s, 1611557 effective words/s\n",
      "2020-03-20 10:23:11,742 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,743 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,743 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,743 : INFO : EPOCH - 7 : training on 58152 raw words (42599 effective words) took 0.0s, 1555207 effective words/s\n",
      "2020-03-20 10:23:11,770 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,771 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,772 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,772 : INFO : EPOCH - 8 : training on 58152 raw words (42718 effective words) took 0.0s, 1573983 effective words/s\n",
      "2020-03-20 10:23:11,797 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,800 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,800 : INFO : EPOCH - 9 : training on 58152 raw words (42735 effective words) took 0.0s, 1565590 effective words/s\n",
      "2020-03-20 10:23:11,826 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,827 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,827 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,828 : INFO : EPOCH - 10 : training on 58152 raw words (42662 effective words) took 0.0s, 1642732 effective words/s\n",
      "2020-03-20 10:23:11,852 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,854 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,855 : INFO : EPOCH - 11 : training on 58152 raw words (42742 effective words) took 0.0s, 1650702 effective words/s\n",
      "2020-03-20 10:23:11,879 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,880 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,881 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,881 : INFO : EPOCH - 12 : training on 58152 raw words (42720 effective words) took 0.0s, 1658686 effective words/s\n",
      "2020-03-20 10:23:11,912 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,913 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,913 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,914 : INFO : EPOCH - 13 : training on 58152 raw words (42684 effective words) took 0.0s, 1373440 effective words/s\n",
      "2020-03-20 10:23:11,940 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,941 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,942 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,942 : INFO : EPOCH - 14 : training on 58152 raw words (42736 effective words) took 0.0s, 1572227 effective words/s\n",
      "2020-03-20 10:23:11,969 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,969 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,969 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,970 : INFO : EPOCH - 15 : training on 58152 raw words (42684 effective words) took 0.0s, 1615507 effective words/s\n",
      "2020-03-20 10:23:11,994 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:11,995 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:11,996 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:11,997 : INFO : EPOCH - 16 : training on 58152 raw words (42643 effective words) took 0.0s, 1658804 effective words/s\n",
      "2020-03-20 10:23:12,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,025 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,027 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,027 : INFO : EPOCH - 17 : training on 58152 raw words (42763 effective words) took 0.0s, 1491971 effective words/s\n",
      "2020-03-20 10:23:12,053 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,054 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,055 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,055 : INFO : EPOCH - 18 : training on 58152 raw words (42733 effective words) took 0.0s, 1579924 effective words/s\n",
      "2020-03-20 10:23:12,082 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,083 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,086 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,086 : INFO : EPOCH - 19 : training on 58152 raw words (42723 effective words) took 0.0s, 1453728 effective words/s\n",
      "2020-03-20 10:23:12,113 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,115 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,115 : INFO : EPOCH - 20 : training on 58152 raw words (42726 effective words) took 0.0s, 1545540 effective words/s\n",
      "2020-03-20 10:23:12,142 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,151 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,152 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,153 : INFO : EPOCH - 21 : training on 58152 raw words (42669 effective words) took 0.0s, 1199519 effective words/s\n",
      "2020-03-20 10:23:12,179 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,180 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,180 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,180 : INFO : EPOCH - 22 : training on 58152 raw words (42694 effective words) took 0.0s, 1619344 effective words/s\n",
      "2020-03-20 10:23:12,208 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,209 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,210 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,210 : INFO : EPOCH - 23 : training on 58152 raw words (42836 effective words) took 0.0s, 1501774 effective words/s\n",
      "2020-03-20 10:23:12,237 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,238 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,239 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,239 : INFO : EPOCH - 24 : training on 58152 raw words (42767 effective words) took 0.0s, 1545139 effective words/s\n",
      "2020-03-20 10:23:12,264 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,265 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,266 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,266 : INFO : EPOCH - 25 : training on 58152 raw words (42627 effective words) took 0.0s, 1645286 effective words/s\n",
      "2020-03-20 10:23:12,293 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,297 : INFO : EPOCH - 26 : training on 58152 raw words (42727 effective words) took 0.0s, 1483478 effective words/s\n",
      "2020-03-20 10:23:12,323 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,324 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,326 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,326 : INFO : EPOCH - 27 : training on 58152 raw words (42718 effective words) took 0.0s, 1509021 effective words/s\n",
      "2020-03-20 10:23:12,353 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,354 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,354 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,355 : INFO : EPOCH - 28 : training on 58152 raw words (42708 effective words) took 0.0s, 1574689 effective words/s\n",
      "2020-03-20 10:23:12,383 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,383 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,384 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,384 : INFO : EPOCH - 29 : training on 58152 raw words (42658 effective words) took 0.0s, 1539718 effective words/s\n",
      "2020-03-20 10:23:12,409 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,410 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,412 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,412 : INFO : EPOCH - 30 : training on 58152 raw words (42792 effective words) took 0.0s, 1592344 effective words/s\n",
      "2020-03-20 10:23:12,441 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,441 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,443 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,444 : INFO : EPOCH - 31 : training on 58152 raw words (42591 effective words) took 0.0s, 1409619 effective words/s\n",
      "2020-03-20 10:23:12,470 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,471 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,472 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,472 : INFO : EPOCH - 32 : training on 58152 raw words (42689 effective words) took 0.0s, 1566181 effective words/s\n",
      "2020-03-20 10:23:12,499 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,500 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,500 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,501 : INFO : EPOCH - 33 : training on 58152 raw words (42604 effective words) took 0.0s, 1566679 effective words/s\n",
      "2020-03-20 10:23:12,529 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,530 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,530 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,531 : INFO : EPOCH - 34 : training on 58152 raw words (42661 effective words) took 0.0s, 1528225 effective words/s\n",
      "2020-03-20 10:23:12,560 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,563 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,565 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,565 : INFO : EPOCH - 35 : training on 58152 raw words (42659 effective words) took 0.0s, 1288435 effective words/s\n",
      "2020-03-20 10:23:12,594 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,595 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,596 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,597 : INFO : EPOCH - 36 : training on 58152 raw words (42652 effective words) took 0.0s, 1428323 effective words/s\n",
      "2020-03-20 10:23:12,627 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,631 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,632 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,632 : INFO : EPOCH - 37 : training on 58152 raw words (42657 effective words) took 0.0s, 1245268 effective words/s\n",
      "2020-03-20 10:23:12,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,664 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,665 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,665 : INFO : EPOCH - 38 : training on 58152 raw words (42664 effective words) took 0.0s, 1345773 effective words/s\n",
      "2020-03-20 10:23:12,692 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,693 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,694 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,694 : INFO : EPOCH - 39 : training on 58152 raw words (42642 effective words) took 0.0s, 1546697 effective words/s\n",
      "2020-03-20 10:23:12,722 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-20 10:23:12,723 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-20 10:23:12,723 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-20 10:23:12,724 : INFO : EPOCH - 40 : training on 58152 raw words (42816 effective words) took 0.0s, 1517021 effective words/s\n",
      "2020-03-20 10:23:12,724 : INFO : training on a 2326080 raw words (1707893 effective words) took 1.3s, 1362570 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab['penalty'].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06732272 -0.12476047  0.11916967 -0.02924351 -0.3081726   0.2028\n",
      "  0.00062394  0.10252877 -0.19012024 -0.09102704 -0.02804117  0.04043559\n",
      "  0.0432324  -0.03685858 -0.11482809  0.2632684   0.07519898 -0.16111656\n",
      "  0.30788338 -0.00605491  0.11093695 -0.03716284 -0.15965474 -0.11657619\n",
      "  0.19527799 -0.10133257  0.02801606 -0.1710302   0.05739621 -0.04919119\n",
      "  0.02137833 -0.0624913   0.01614645  0.255878    0.1485272   0.08676764\n",
      "  0.0472293   0.09611478  0.0510371   0.07610098  0.09373116 -0.09922076\n",
      "  0.00806367 -0.01895287  0.20629326  0.12039571 -0.21268377 -0.06012771\n",
      " -0.01002343 -0.04122327]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the Model\n",
    "\n",
    "To assess our new model, we’ll first infer new vectors for each document of the training corpus, compare the inferred vectors with the training corpus, and then returning the rank of the document based on self-similarity. Basically, we’re pretending as if the training corpus is some new unseen data and then seeing how they compare with the trained model. The expectation is that we’ve likely overfit our model (i.e., all of the ranks will be less than 2) and so we should be able to find similar documents very easily. Additionally, we’ll keep track of the second ranks for a comparison of less similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-20 10:36:35,939 : INFO : precomputing L2-norms of doc weight vectors\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn = len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 291, 1: 9})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, greater than 95% of the inferred documents are found to be most similar to itself and about 5% of the time it is mistakenly most similar to another document. Checking the inferred-vector against a training-vector is a sort of ‘sanity check’ as to whether the model is behaving in a usefully consistent manner, though not a real ‘accuracy’ value.\n",
    "\n",
    "This is great and not entirely surprising. We can take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (299): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (299, 0.9302384853363037): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "SECOND-MOST (112, 0.8083556890487671): «australian cricket captain steve waugh has supported fast bowler brett lee after criticism of his intimidatory bowling to the south african tailenders in the first test in adelaide earlier this month lee was fined for giving new zealand tailender shane bond an unsportsmanlike send off during the third test in perth waugh says tailenders should not be protected from short pitched bowling these days you re earning big money you ve got responsibility to learn how to bat he said mean there no times like years ago when it was not professional and sort of bowlers code these days you re professional our batsmen work very hard at their batting and expect other tailenders to do likewise meanwhile waugh says his side will need to guard against complacency after convincingly winning the first test by runs waugh says despite the dominance of his side in the first test south africa can never be taken lightly it only one test match out of three or six whichever way you want to look at it so there lot of work to go he said but it nice to win the first battle definitely it gives us lot of confidence going into melbourne you know the big crowd there we love playing in front of the boxing day crowd so that will be to our advantage as well south africa begins four day match against new south wales in sydney on thursday in the lead up to the boxing day test veteran fast bowler allan donald will play in the warm up match and is likely to take his place in the team for the second test south african captain shaun pollock expects much better performance from his side in the melbourne test we still believe that we didn play to our full potential so if we can improve on our aspects the output we put out on the field will be lot better and we still believe we have side that is good enough to beat australia on our day he said»\n",
      "\n",
      "MEDIAN (137, 0.28144264221191406): «striking latrobe valley power workers will meet today to consider ongoing industrial action the company yallourn energy believes victoria power supply is under threat sixty five maintenance workers downed tools two weeks ago over job security terry lee from the australian workers union fears up to jobs at the plant are at risk mr lee says the strike action has been timed to avoid power supply interruptions in victoria the only power that will be interrupted is the power yallourn energy would at this time like to be selling into the market he said but yallourn energy mine manager lindsay ward says all power generation at the plant has been halted and blackouts are possible mr ward admits about jobs at the plant will go when the company modernises its coal mining operations»\n",
      "\n",
      "LEAST (85, -0.12133777886629105): «hamas militants have fought gun battles with palestinian security forces in the gaza strip trying to arrest one of the islamic group senior political leaders reports say the fight erupted in the gaza strip after dozens of hamas members surrounded the home of abdel aziz al rantissi when palestinian police arrived to detain him the palestinian leader yasser arafat under international pressure to crack down on militants after wave of suicide bombings in israel in the past month has outlawed the military wings of hamas and other groups and arrested dozens of militants»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (260): «traveland wholly owned travel centres have ceased operating from today leaving more than staff seeking other jobs the failed company administrators say they have buyer for traveland franchise network but have not been able to save the company stores one of the administrators richard albarran says the deal which is yet to be approved by committee formed today of creditors will unfortunately leave hundreds of people who have booked holidays through the company stores out of pocket the dollar value is approximately tad over million mr albarran said they will now be entitled to make claims through the travel compensation fund the meeting of company creditors was told this morning staff are owed nearly million in entitlements the australian services union luke foley says he will be doing everything he can to ensure they receive every cent ansett administrators are liable for perhaps the lion share of those employee entitlements we re confident that ll be met mr foley said and more than staff are to lose their jobs at australia biggest regional pay television operator austar the company has this morning announced wide ranging restructuring plans management at the struggling pay tv operator has now completed review of all its activities as result of this review the austar board has decided to outsource number of existing functions cease operating its own internet network and streamline other processes the company anticipates annualised savings of around million more than staff will be made redundant from the end of december austar has given assurances that redundant workers will receive their full entitlements and redundancy payments in line with company policy the company says they will receive all statutory entitlements and redundancy payments in line with company policy on the stock exchange austar shares rose five cents to cents shortly before pm aedt»\n",
      "\n",
      "Similar Document (195, 0.7808316946029663): «unions representing qantas maintenance workers have not ruled out disruptions to christmas flights following breakdown in negotiations with management the issue of wage freeze was not resolved after two days of hearings before the industrial relations commission qantas has put an offer to workers but unions will advise members to reject it because it does not include pay rise doug cameron from the australian manufacturing workers union says qantas is being greedy any disruption to christmas flights is clearly on the head of qantas he said qantas have been the company that have been absolutely belligerent in their approach towards their own employees qantas are the company that are trying to cut the wages of the lowest paid skilled workers in the country and qantas is the company that have created this situation and they have come and not moved one inch in bargaining unions say maintenance workers deserve modest pay rises and an improved career structure but qantas maintains it has to impose wage freeze because of the global downturn in the airline industry doug cameron from the manufacturing workers union says members will decide by secret ballot whether to step up industrial action every time qantas has come to the table they ve been arrogant they ve been belligerent he said their position is that these workers will bow to the will of qantas and our view is that is unacceptable for company that built its reputation for safety built its reputation for reliability on the back of the workers who are earning year qantas says it is confident an agreement will be reached following the secret ballot»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "import random\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model\n",
    "\n",
    "Using the same approach above, we’ll infer the vector for a randomly chosen test document, and compare the document to our model by eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (24): «nigerian president olusegun obasanjo said he will weep if single mother sentenced to death by stoning for having child out of wedlock is killed but added he has faith the court system will overturn her sentence obasanjo comments late saturday appeared to confirm he would not intervene directly in the case despite an international outcry»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (23, 0.7190220355987549): «americans fears about airplane security continue to increase after man made it through two separate flights with loaded gun in his carry on luggage the man was finally stopped before boarding third plane in memphis the man had travelled from florida to atlanta and then atlanta to memphis he was attempting to board his return flight last night when he was stopped by security personnel for random check they discovered loaded mm beretta semi automatic pistol in his hand luggage the man acknowledged the gun was his and was released on bail there is no suggestion he was planning any sort of terrorist attack but his ability to complete two flights while carrying the weapon has again highlighted airline security problems the incident follows last week drama when man was able to board plane from paris to miami with explosives in his shoes»\n",
      "\n",
      "MEDIAN (279, 0.32241442799568176): «forward indicators of the australian labour market are failing to improve with further decline in newspaper employment advertising the anz bank job advertisement series has measured per cent fall in the number of employment notices placed in major daily newspapers during november anz chief economist saul eslake says it is the third drop in row to just under per week on average the lowest level since march he says the survey points to national unemployment rate of per cent early in the new year and provides added justification for cut in official interest rates this week meanwhile the olivier recruitment group measure of internet job advertising has recorded its biggest drop since it was started almost two years ago it has dropped per cent following per cent fall in october the latest result suggests fewer jobs were advertised in cyberspace during november the olivier internet job index is now the lowest it has ever been the company director robert olivier describes the job market in australia as shot to pieces»\n",
      "\n",
      "LEAST (40, -0.1555093377828598): «firefighters across new south wales are gearing up for wind change that may bring further property losses today more than fires now ring two thirds of the greater sydney area the blazes stretch south of the royal national park and north of wollongong all the way to the blue mountains and up towards the edge of the baulkham hills shire fires are also burning around huskisson on the far south coast and as far inland as mudgee narromine and kempsey and the richmond valley in the north however the major areas of concern today are the southern sydney suburbs of heathcote and engadine thousands of residents in those suburbs were evacuated overnight senior forecaster with the sydney weather bureau ian robertson says the greatest risk will come when winds change direction this afternoon we re looking at another dry day ahead throughout the state particularly along the coast more average sort of temperatures but the trick will be the winds mr robertson said we re looking at south west winds this morning an east to south east sea breeze along the coast which is going to make things quite challenging for firefighting between and firefighters are currently battling the blazes crews have already been brought in from victoria but the rural fire service says it expects to call on other states for help service spokesman john winter says property losses have been high we are estimating that around homes have been lost obviously there are areas we re yet to confirm property losses mr winter said»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
